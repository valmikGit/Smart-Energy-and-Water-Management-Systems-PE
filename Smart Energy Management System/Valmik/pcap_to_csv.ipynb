{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mqtt_pcap_to_csv.py\n",
    "# Standalone script to convert pcap files into packet, uniflow, and biflow CSV feature sets\n",
    "# Produces folders: packet_features, uniflow_features, biflow_features\n",
    "# Each folder contains 5 CSVs: normal, sparta, scan_A, mqtt_bruteforce, scan_sU\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from scapy.all import rdpcap, IP, TCP, UDP\n",
    "from collections import defaultdict\n",
    "\n",
    "# ------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------\n",
    "INPUT_PCAPS = {\n",
    "    \"normal\": \"normal.pcap\",\n",
    "    \"sparta\": \"sparta.pcap\",\n",
    "    \"scan_A\": \"scan_A.pcap\",\n",
    "    \"mqtt_bruteforce\": \"mqtt_bruteforce.pcap\",\n",
    "    \"scan_sU\": \"scan_sU.pcap\",\n",
    "}\n",
    "OUTPUT_DIRS = {\n",
    "    \"packet\": \"packet_features\",\n",
    "    \"uniflow\": \"uniflow_features\",\n",
    "    \"biflow\": \"biflow_features\"\n",
    "}\n",
    "\n",
    "# Ensure output dirs exist\n",
    "for folder in OUTPUT_DIRS.values():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# FEATURE EXTRACTION HELPERS\n",
    "# ------------------------------\n",
    "\n",
    "def extract_packet_features(packets):\n",
    "    \"\"\"Extract raw packet-level features into a DataFrame\"\"\"\n",
    "    rows = []\n",
    "    for p in packets:\n",
    "        if IP not in p:\n",
    "            continue\n",
    "        ip = p[IP]\n",
    "        proto = ip.proto\n",
    "        length = len(p)\n",
    "\n",
    "        row = {\n",
    "            \"src_ip\": ip.src,\n",
    "            \"dst_ip\": ip.dst,\n",
    "            \"protocol\": proto,\n",
    "            \"packet_len\": length,\n",
    "            \"ttl\": ip.ttl\n",
    "        }\n",
    "        if TCP in p:\n",
    "            row.update({\n",
    "                \"sport\": p[TCP].sport,\n",
    "                \"dport\": p[TCP].dport,\n",
    "                \"flags\": int(p[TCP].flags)\n",
    "            })\n",
    "        elif UDP in p:\n",
    "            row.update({\n",
    "                \"sport\": p[UDP].sport,\n",
    "                \"dport\": p[UDP].dport\n",
    "            })\n",
    "        else:\n",
    "            row.update({\"sport\": 0, \"dport\": 0, \"flags\": 0})\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def extract_uniflow_features(packets):\n",
    "    \"\"\"Aggregate features per unidirectional flow\"\"\"\n",
    "    flows = defaultdict(list)\n",
    "    for p in packets:\n",
    "        if IP not in p:\n",
    "            continue\n",
    "        ip = p[IP]\n",
    "        proto = ip.proto\n",
    "        if TCP in p:\n",
    "            key = (ip.src, ip.dst, p[TCP].sport, p[TCP].dport, proto)\n",
    "            plen = len(p)\n",
    "        elif UDP in p:\n",
    "            key = (ip.src, ip.dst, p[UDP].sport, p[UDP].dport, proto)\n",
    "            plen = len(p)\n",
    "        else:\n",
    "            continue\n",
    "        flows[key].append(plen)\n",
    "\n",
    "    rows = []\n",
    "    for (src, dst, sport, dport, proto), sizes in flows.items():\n",
    "        row = {\n",
    "            \"src_ip\": src,\n",
    "            \"dst_ip\": dst,\n",
    "            \"sport\": sport,\n",
    "            \"dport\": dport,\n",
    "            \"protocol\": proto,\n",
    "            \"pkt_count\": len(sizes),\n",
    "            \"bytes_total\": sum(sizes),\n",
    "            \"bytes_mean\": sum(sizes) / len(sizes)\n",
    "        }\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def extract_biflow_features(packets):\n",
    "    \"\"\"Aggregate features per bidirectional flow (ignores direction)\"\"\"\n",
    "    flows = defaultdict(list)\n",
    "    for p in packets:\n",
    "        if IP not in p:\n",
    "            continue\n",
    "        ip = p[IP]\n",
    "        proto = ip.proto\n",
    "        if TCP in p:\n",
    "            key = tuple(sorted([(ip.src, p[TCP].sport), (ip.dst, p[TCP].dport)])) + (proto,)\n",
    "            plen = len(p)\n",
    "        elif UDP in p:\n",
    "            key = tuple(sorted([(ip.src, p[UDP].sport), (ip.dst, p[UDP].dport)])) + (proto,)\n",
    "            plen = len(p)\n",
    "        else:\n",
    "            continue\n",
    "        flows[key].append(plen)\n",
    "\n",
    "    rows = []\n",
    "    for key, sizes in flows.items():\n",
    "        ((a_ip, a_port), (b_ip, b_port), proto) = key\n",
    "        row = {\n",
    "            \"endA_ip\": a_ip,\n",
    "            \"endA_port\": a_port,\n",
    "            \"endB_ip\": b_ip,\n",
    "            \"endB_port\": b_port,\n",
    "            \"protocol\": proto,\n",
    "            \"pkt_count\": len(sizes),\n",
    "            \"bytes_total\": sum(sizes),\n",
    "            \"bytes_mean\": sum(sizes) / len(sizes)\n",
    "        }\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# MAIN PIPELINE\n",
    "# ------------------------------\n",
    "\n",
    "def process_pcap(label, filepath):\n",
    "    print(f\"[INFO] Processing {label}: {filepath}\")\n",
    "    packets = rdpcap(filepath)\n",
    "\n",
    "    # Extract features\n",
    "    df_packet = extract_packet_features(packets)\n",
    "    df_uniflow = extract_uniflow_features(packets)\n",
    "    df_biflow = extract_biflow_features(packets)\n",
    "\n",
    "    # Save to CSV in expected structure\n",
    "    df_packet.to_csv(os.path.join(OUTPUT_DIRS[\"packet\"], f\"{label}.csv\"), index=False)\n",
    "    df_uniflow.to_csv(os.path.join(OUTPUT_DIRS[\"uniflow\"], f\"uniflow_{label}.csv\"), index=False)\n",
    "    df_biflow.to_csv(os.path.join(OUTPUT_DIRS[\"biflow\"], f\"biflow_{label}.csv\"), index=False)\n",
    "\n",
    "    print(f\"[OK] Saved features for {label}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for label, fname in INPUT_PCAPS.items():\n",
    "        if not os.path.isfile(fname):\n",
    "            print(f\"[WARN] File {fname} not found, skipping.\")\n",
    "            continue\n",
    "        process_pcap(label, fname)\n",
    "\n",
    "    print(\"[DONE] All pcaps processed. Features are in packet_features/, uniflow_features/, biflow_features/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seawsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
