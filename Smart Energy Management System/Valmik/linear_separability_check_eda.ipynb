{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad1a23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Chosen features: 'ttl' and 'ip_len' (from ./packet_features\\normal.csv)\n",
      "[SAMPLED] 20000/20000 points collected...\n",
      "[DONE] Collected 20000 points for plotting.\n",
      "[SAVED] Combined scatter saved to: outputs_scatter\\combined_scatter.png\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\0aaf6103-e421-47be-a08d-275a36fc6fe8.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\0aaf6103-e421-47be-a08d-275a36fc6fe8.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\10dc3b92-bb32-419f-8837-66bc69d2cf90.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\10dc3b92-bb32-419f-8837-66bc69d2cf90.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\1cef3d27-3501-41ad-9004-ce7b2e5e72c2.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\1cef3d27-3501-41ad-9004-ce7b2e5e72c2.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\29acb3a2-ae9f-4900-bbe8-e6f9d7d72d33.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\29acb3a2-ae9f-4900-bbe8-e6f9d7d72d33.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\2c834245-76ab-4418-ab84-19b4a946bd48.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\2c834245-76ab-4418-ab84-19b4a946bd48.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\3cecd22f-5a39-4efa-976d-2b825852d09e.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\3cecd22f-5a39-4efa-976d-2b825852d09e.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\7430c487-e975-4a78-998f-0b8f81872b56.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\7430c487-e975-4a78-998f-0b8f81872b56.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\945ca6cd-44d0-4543-b1ca-012ce1497ccf.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\945ca6cd-44d0-4543-b1ca-012ce1497ccf.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\9b315e51-b42d-44ac-8df0-59446d4602e2.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\9b315e51-b42d-44ac-8df0-59446d4602e2.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\bc703641-cb17-48ba-8003-5b423dbd53da.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\bc703641-cb17-48ba-8003-5b423dbd53da.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\bf968483-477c-47c8-9744-1f6ce295c4fe.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\bf968483-477c-47c8-9744-1f6ce295c4fe.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\c1b3ea3a-8fae-4e2c-8260-a66e0e491a4d.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\c1b3ea3a-8fae-4e2c-8260-a66e0e491a4d.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\d0ae5af0-1c5f-4418-a4e0-5e1f0c4eb956.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\d0ae5af0-1c5f-4418-a4e0-5e1f0c4eb956.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\d3fea273-5eaa-421a-a790-437f68f45d76.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\d3fea273-5eaa-421a-a790-437f68f45d76.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\d437eaed-f91f-457a-b3d5-1b56e8938177.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\d437eaed-f91f-457a-b3d5-1b56e8938177.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\e2f88626-7dc3-4f68-90b6-3d00bad14028.tmp: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\e2f88626-7dc3-4f68-90b6-3d00bad14028.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\is-5P7RE.tmp: [WinError 5] Access is denied: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\is-5P7RE.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\is-PIQ4J.tmp: [WinError 5] Access is denied: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\is-PIQ4J.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\~nsu1.tmp: [WinError 5] Access is denied: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\~nsu1.tmp'\n",
      "[CLEANUP] Could not remove C:\\Users\\VALMIK~1\\AppData\\Local\\Temp\\~nsu2.tmp: [WinError 5] Access is denied: 'C:\\\\Users\\\\VALMIK~1\\\\AppData\\\\Local\\\\Temp\\\\~nsu2.tmp'\n",
      "[CLEANUP] No temp files found to remove.\n",
      "\n",
      "[SUCCESS] Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Memory-safe single scatter plot for linearly separability check (attack vs no-attack).\n",
    "\n",
    "This script:\n",
    " - Streams CSV files in chunks (no full concat)\n",
    " - Selects two numeric columns (from the first chunk that has >=2 numeric features)\n",
    " - Randomly samples up to MAX_POINTS combined across all files\n",
    " - Produces one scatter plot (saved to OUTPUT_DIR/combined_scatter.png)\n",
    " - Cleans up temporary *.tmp / *.temp files in the system temp dir and base folder\n",
    "\n",
    "EDIT:\n",
    " - MAX_POINTS controls how many points will be drawn in total (default 20000)\n",
    " - CHUNK_SIZE controls pandas chunk size when streaming (default 50k)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import tempfile\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------\n",
    "# Config\n",
    "# ------------------------------\n",
    "base_path = \"./\"   # root folder where feature folders live\n",
    "folders = {\n",
    "    \"packet\": \"packet_features\",\n",
    "    \"uniflow\": \"uniflow_features\",\n",
    "    \"biflow\": \"biflow_features\"\n",
    "}\n",
    "files = {\n",
    "    \"normal\": \"normal.csv\",\n",
    "    \"sparta\": \"sparta.csv\",\n",
    "    \"scan_A\": \"scan_A.csv\",\n",
    "    \"mqtt_bruteforce\": \"mqtt_bruteforce.csv\",\n",
    "    \"scan_sU\": \"scan_sU.csv\"\n",
    "}\n",
    "def build_filenames(prefix):\n",
    "    return {\n",
    "        \"normal\": f\"{prefix}_normal.csv\",\n",
    "        \"sparta\": f\"{prefix}_sparta.csv\",\n",
    "        \"scan_A\": f\"{prefix}_scan_A.csv\",\n",
    "        \"mqtt_bruteforce\": f\"{prefix}_mqtt_bruteforce.csv\",\n",
    "        \"scan_sU\": f\"{prefix}_scan_sU.csv\"\n",
    "    }\n",
    "feature_files = {\n",
    "    \"packet\": files,\n",
    "    \"uniflow\": build_filenames(\"uniflow\"),\n",
    "    \"biflow\": build_filenames(\"biflow\")\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = \"outputs_scatter\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CHUNK_SIZE = 50000      # pandas read_csv chunksize\n",
    "MAX_POINTS = 20000      # total points to sample across all files (keep small to avoid memory)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------------\n",
    "# Helper: find two numeric columns to plot\n",
    "# ------------------------------\n",
    "def find_two_numeric_columns(feature_files_map, base_path, chunksize=CHUNK_SIZE):\n",
    "    \"\"\"\n",
    "    Scan files until we find a chunk with >= 2 numeric columns.\n",
    "    Returns (x_col, y_col) or (None, None) if not found.\n",
    "    \"\"\"\n",
    "    for level, file_dict in feature_files_map.items():\n",
    "        folder_path = os.path.join(base_path, folders[level])\n",
    "        for name, fname in file_dict.items():\n",
    "            fpath = os.path.join(folder_path, fname)\n",
    "            if not os.path.exists(fpath):\n",
    "                continue\n",
    "            try:\n",
    "                for chunk in pd.read_csv(fpath, chunksize=chunksize, low_memory=False):\n",
    "                    numeric_cols = chunk.select_dtypes(include=[np.number]).columns.tolist()\n",
    "                    # drop 'label' if present (we'll assign label per file later)\n",
    "                    numeric_cols = [c for c in numeric_cols if c.lower() != \"label\"]\n",
    "                    if len(numeric_cols) >= 2:\n",
    "                        print(f\"[INFO] Chosen features: '{numeric_cols[0]}' and '{numeric_cols[1]}' (from {fpath})\")\n",
    "                        return numeric_cols[0], numeric_cols[1]\n",
    "                    # otherwise go to next chunk/file\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Could not read {fpath}: {e}\")\n",
    "                continue\n",
    "    return None, None\n",
    "\n",
    "# ------------------------------\n",
    "# Streaming sampler\n",
    "# ------------------------------\n",
    "def stream_and_sample(feature_files_map, base_path, x_col, y_col, max_points=MAX_POINTS, chunksize=CHUNK_SIZE):\n",
    "    \"\"\"\n",
    "    Streams CSVs chunk-by-chunk and samples up to max_points (combined).\n",
    "    Returns arrays (X_vals shape=(n,2), labels shape=(n,))\n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    labels = []\n",
    "    total_collected = 0\n",
    "    stop_all = False\n",
    "\n",
    "    for level, file_dict in feature_files_map.items():\n",
    "        folder_path = os.path.join(base_path, folders[level])\n",
    "        for name, fname in file_dict.items():\n",
    "            if stop_all:\n",
    "                break\n",
    "            fpath = os.path.join(folder_path, fname)\n",
    "            if not os.path.exists(fpath):\n",
    "                continue\n",
    "            label = 0 if name == \"normal\" else 1\n",
    "            try:\n",
    "                for chunk in pd.read_csv(fpath, chunksize=chunksize, low_memory=False):\n",
    "                    # if we've collected enough, break out\n",
    "                    remaining = max_points - total_collected\n",
    "                    if remaining <= 0:\n",
    "                        stop_all = True\n",
    "                        break\n",
    "\n",
    "                    # If the desired columns are present, use them; otherwise skip this chunk\n",
    "                    if x_col not in chunk.columns or y_col not in chunk.columns:\n",
    "                        # try to coerce by selecting first two numeric columns in this chunk\n",
    "                        numeric_cols = chunk.select_dtypes(include=[np.number]).columns.tolist()\n",
    "                        numeric_cols = [c for c in numeric_cols if c.lower() != \"label\"]\n",
    "                        if len(numeric_cols) >= 2:\n",
    "                            use_x, use_y = numeric_cols[0], numeric_cols[1]\n",
    "                        else:\n",
    "                            # nothing usable in this chunk\n",
    "                            continue\n",
    "                    else:\n",
    "                        use_x, use_y = x_col, y_col\n",
    "\n",
    "                    sub = chunk[[use_x, use_y]].dropna()\n",
    "                    if sub.shape[0] == 0:\n",
    "                        continue\n",
    "\n",
    "                    # how many samples to draw from this chunk\n",
    "                    # draw up to remaining, but also up to a fraction of the chunk (to get distribution across chunks)\n",
    "                    # here we draw min(remaining, len(sub))\n",
    "                    n_draw = min(remaining, len(sub))\n",
    "                    # rand sample indices\n",
    "                    if n_draw < len(sub):\n",
    "                        idx = np.random.choice(sub.index.values, size=n_draw, replace=False)\n",
    "                        sample = sub.loc[idx].values\n",
    "                    else:\n",
    "                        sample = sub.values\n",
    "\n",
    "                    x_vals = sample[:, 0].astype(np.float64)\n",
    "                    y_vals = sample[:, 1].astype(np.float64)\n",
    "                    xs.extend(x_vals.tolist())\n",
    "                    ys.extend(y_vals.tolist())\n",
    "                    labels.extend([label] * len(x_vals))\n",
    "                    total_collected += len(x_vals)\n",
    "\n",
    "                    # quick progress note\n",
    "                    if total_collected % 1000 == 0:\n",
    "                        print(f\"[SAMPLED] {total_collected}/{max_points} points collected...\")\n",
    "\n",
    "                    if total_collected >= max_points:\n",
    "                        stop_all = True\n",
    "                        break\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"[WARN] {fpath} is empty, skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Error streaming {fpath}: {e}\")\n",
    "        if stop_all:\n",
    "            break\n",
    "\n",
    "    if total_collected == 0:\n",
    "        raise RuntimeError(\"No samples collected from the dataset. Check that numeric features exist.\")\n",
    "\n",
    "    X = np.column_stack((np.array(xs), np.array(ys)))\n",
    "    y = np.array(labels, dtype=np.int32)\n",
    "    print(f\"[DONE] Collected {X.shape[0]} points for plotting.\")\n",
    "    return X, y\n",
    "\n",
    "# ------------------------------\n",
    "# Plotting\n",
    "# ------------------------------\n",
    "def plot_scatter(X, y, x_label, y_label, out_path):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    idx_no = (y == 0)\n",
    "    idx_yes = (y == 1)\n",
    "    plt.scatter(X[idx_no, 0], X[idx_no, 1], c=\"blue\", label=\"No Attack\", alpha=0.5, s=8)\n",
    "    plt.scatter(X[idx_yes, 0], X[idx_yes, 1], c=\"red\", label=\"Attack\", alpha=0.5, s=8)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(f\"Scatter ({x_label} vs {y_label}) â€” attack vs no-attack\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "    print(f\"[SAVED] Combined scatter saved to: {out_path}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Cleanup temp files (.tmp/.temp)\n",
    "# ------------------------------\n",
    "def cleanup_temp_files(base_dirs=None):\n",
    "    if base_dirs is None:\n",
    "        base_dirs = [tempfile.gettempdir(), base_path]\n",
    "    patterns = [\"*.tmp\", \"*.temp\"]\n",
    "    removed = 0\n",
    "    for d in base_dirs:\n",
    "        for pat in patterns:\n",
    "            for f in glob.glob(os.path.join(d, pat)):\n",
    "                try:\n",
    "                    os.remove(f)\n",
    "                    removed += 1\n",
    "                    print(f\"[CLEANUP] Removed temp file: {f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[CLEANUP] Could not remove {f}: {e}\")\n",
    "    if removed == 0:\n",
    "        print(\"[CLEANUP] No temp files found to remove.\")\n",
    "    else:\n",
    "        print(f\"[CLEANUP] Removed {removed} temp files.\")\n",
    "\n",
    "# ------------------------------\n",
    "# Main\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Find two numeric columns to use\n",
    "    x_col, y_col = find_two_numeric_columns(feature_files, base_path, chunksize=CHUNK_SIZE)\n",
    "    if x_col is None or y_col is None:\n",
    "        print(\"[ERROR] Could not find two numeric columns to plot in the dataset.\")\n",
    "        raise SystemExit(1)\n",
    "\n",
    "    # 2) Stream and sample up to MAX_POINTS\n",
    "    X_sampled, y_sampled = stream_and_sample(feature_files, base_path, x_col, y_col, max_points=MAX_POINTS, chunksize=CHUNK_SIZE)\n",
    "\n",
    "    # 3) Plot combined scatter\n",
    "    out_file = os.path.join(OUTPUT_DIR, \"combined_scatter.png\")\n",
    "    plot_scatter(X_sampled, y_sampled, x_col, y_col, out_file)\n",
    "\n",
    "    # 4) Cleanup temp files\n",
    "    cleanup_temp_files([tempfile.gettempdir(), base_path])\n",
    "\n",
    "    print(\"\\n[SUCCESS] Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seawsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
